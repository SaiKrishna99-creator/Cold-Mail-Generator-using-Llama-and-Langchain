{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "import uuid\n",
        "import re\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "groq_api_key = 'Your_API_Key'\n",
        "\n",
        "class Chain:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.llm = ChatGroq(\n",
        "    temperature=0.1,\n",
        "    groq_api_key = 'Your_API_Key',\n",
        "    model_name = 'llama-3.3-70b-versatile')\n",
        "\n",
        "  def extract_jobs(self, clean_txt):\n",
        "    prompt_extract = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        ### SCRAPED TEXT FROM WEBSITE:\n",
        "        {page_data}\n",
        "        ### INSTRUCTION:\n",
        "        The scraped text is from the career's page of a website.\n",
        "        Your job is to extract the job postings and return them in JSON format containing the\n",
        "        following keys: `role`, `experience`, `skills` and `description`.\n",
        "        Only return the valid JSON.\n",
        "        ### VALID JSON (NO PREAMBLE):\n",
        "        \"\"\")\n",
        "\n",
        "    prompt_chain = prompt_extract | self.llm\n",
        "    res = prompt_chain.invoke(input={'page_data':clean_txt})\n",
        "\n",
        "    try:\n",
        "      json_parser = JsonOutputParser()\n",
        "      res = json_parser.parse(res.content)\n",
        "    except OutputParserException:\n",
        "      raise OutputParserException('Context too big to handle.')\n",
        "    return res if isinstance(res, list) else [res]\n",
        "\n",
        "  def write_mail(self, job, links):\n",
        "    prompt_mail = PromptTemplate.from_template('''\n",
        "      ### JOB DESCRIPTION:\n",
        "      {job_description}\n",
        "\n",
        "      ### INSTRUCTION:\n",
        "      You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
        "      the seamless integration of business processes through automated tools.\n",
        "      Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability,\n",
        "      process optimization, cost reduction, and heightened overall efficiency.\n",
        "      Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ\n",
        "      in fulfilling their needs.\n",
        "      Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
        "      Remember you are Mohan, BDE at AtliQ.\n",
        "      Do not provide a preamble.\n",
        "      ### EMAIL (NO PREAMBLE):\n",
        "    ''')\n",
        "\n",
        "    chain_mail = prompt_mail | self.llm\n",
        "    res = chain_mail.invoke({'job_description': str(job), 'link_list': links})\n",
        "    return res.content\n",
        "\n",
        "\n",
        "class Portfolio:\n",
        "\n",
        "  def __init__(self, file_path = 'my_portfolio.csv'):\n",
        "    self.file_path = file_path\n",
        "    self.data = pd.read_csv(self.file_path)\n",
        "    self.chroma_client = chromadb.PersistentClient('vectorstores')\n",
        "    self.new_collection = self.chroma_client.get_or_create_collection(name = 'portfolios')\n",
        "\n",
        "  def load_portfolio(self):\n",
        "      if not self.new_collection.count():\n",
        "          for _, row in self.data.iterrows():\n",
        "              self.new_collection.add(documents=row[\"Techstack\"],\n",
        "                                    metadatas={\"links\": row[\"Links\"]},\n",
        "                                    ids=[str(uuid.uuid4())])\n",
        "  def query_links(self, skills):\n",
        "    return self.new_collection.query(query_texts=skills, n_results=2).get('metadatas',[])\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<[^>]*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    # Trim leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "def create_streamlit(llm, portfolio, clean_text):\n",
        "\n",
        "  st.title('Cold Mail Generator')\n",
        "  url_input = st.text_input('Enter a valid URL here')\n",
        "  submit_button = st.button('Submit')\n",
        "\n",
        "  if submit_button:\n",
        "\n",
        "    try:\n",
        "      webload = WebBaseLoader([url_input])\n",
        "      data = clean_text(webload.load().pop().page_content)\n",
        "      portfolio.load_portfolio()\n",
        "      jobs = llm.extract_jobs(data)\n",
        "      for job in jobs:\n",
        "        skills = job.get('skills',[])\n",
        "        link_1 = portfolio.query_links(skills)\n",
        "        mail_1 = llm.write_mail(job, link_1)\n",
        "        st.code(mail_1,language='markdown')\n",
        "\n",
        "    except Exception as e:\n",
        "      st.error('An error occured: {e}')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chain = Chain()\n",
        "    portfolio = Portfolio()\n",
        "    st.set_page_config(layout=\"wide\", page_title=\"Cold Email Generator\", page_icon=\"ðŸ“§\")\n",
        "    create_streamlit(chain, portfolio, clean_text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz1TMixM4czX",
        "outputId": "4d828ec3-8041-4379-af48-afef3d830a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"334RUSAsc8UUBiEQbpQTLKgMbf8_3ykWUJFt7NvVMv4N1oVqp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96oqEYqgH5k-",
        "outputId": "f1140648-557a-4946-ec53-b1caa1e88cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kill any previous server on 8501, then start Streamlit\n",
        "!fuser -k 8501/tcp >/dev/null 2>&1 || true\n",
        "import subprocess, time\n",
        "p = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "time.sleep(3)  # give it a moment to boot"
      ],
      "metadata": {
        "id": "qyjLB45HH9nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# close any old tunnels and agent\n",
        "for t in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(t.public_url)\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"Streamlit app:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9qtfNzDH--j",
        "outputId": "ff2fa6d4-47f2-4961-f60f-1cd0a9d0fc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-30T19:57:58+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-6d75b848-6419-4ec6-8d0b-2b0e815de29d acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app: NgrokTunnel: \"https://nonprominently-unpredisposing-burton.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}